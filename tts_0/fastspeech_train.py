# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/06-training-fastspeech.ipynb.

# %% auto 0
__all__ = ['TrainFastSpeech', 'ScheduleLR', 'ShowMelCB', 'Hook', 'colorize_mel', 'normalize', 'mel_to_audio', 'WandBCB',
           'count_parameters']

# %% ../nbs/06-training-fastspeech.ipynb 2
from .fastspeech import FastSpeech
from .tts_data import TTSDataset, collate_fn
from torch.utils.data import DataLoader
from functools import partial
from .data import *

# %% ../nbs/06-training-fastspeech.ipynb 3
import torch.nn as nn
from .learn import *
from typing import Callable, Sequence
from torch.nn import Module
from torch import optim
import torch.nn.functional as F
import fastcore.all as fc
from torch import tensor
from torch.optim.lr_scheduler import OneCycleLR
import torch
from fastspeech.visualize import show_mel
from torch import Tensor

# %% ../nbs/06-training-fastspeech.ipynb 4
class TrainFastSpeech(Learner):
    def __init__(self, model: Module, dls: DataLoaders, loss_fn: Callable, loss_fn_b: Callable, lr: float = 0.1, 
                 cbs: Sequence[Callback] = (), optimizer_fn: Callable = optim.SGD) -> None:
        super().__init__(model, dls, loss_fn, lr, cbs, optimizer_fn)
        self.loss_fn_b = loss_fn_b
        
    def predict(self) -> None:
        phones, durations = self.batch[:2]

        self.preds = self.model(phones, durations)
    
    def get_loss(self) -> None:
        d_slice = (slice(None), slice(None, -1))
        durations, mels, mel_alignment, duration_alignment = self.batch[1:]
        bs = mels.shape[0]
        
        self.loss, self.duration_loss = tensor(0.), tensor(0.)
        for i in range(bs):
            mel_slice = (slice(None), slice(None, mel_alignment[i]))
            duration_slice = slice(None, duration_alignment[i])
            
            self.loss += self.loss_fn(self.preds[0][i][mel_slice], mels[i][mel_slice]) / bs
            self.duration_loss += self.loss_fn_b(self.preds[1][i][duration_slice], 
                                                 durations[i][duration_slice].to(torch.float)) / bs
    
    def backward(self) -> None:
        self.loss.backward()
        self.duration_loss.backward()
    
    def step(self) -> None:
        self.optimizer.step()
    
    def zero_grad(self) -> None:
        self.optimizer.zero_grad()

# %% ../nbs/06-training-fastspeech.ipynb 5
class ScheduleLR(Callback):
    def __init__(self, Scheduler, *args, **kwargs):
        super().__init__()
        self.Scheduler = Scheduler
        self.args = args
        self.kwargs = kwargs
        
    def before_fit(self, learn):
        learn.scheduler = self.Scheduler(learn.optimizer, *self.args, **self.kwargs)
        
    def after_batch(self, learn):
        learn.scheduler.step()

# %% ../nbs/06-training-fastspeech.ipynb 6
class ShowMelCB(Callback):
    def __init__(self, xb, n_steps=500):
        super().__init__()
        fc.store_attr()
        self.i = 0
    
    def _show_mel(self):
        with torch.no_grad():
            phones, durations = self.xb[:2]

            mel, _ = learn.model(phones, durations)
        
        show_mel(to_cpu(mel)[0])
        
    def after_batch(self, learn):
        if self.i % self.n_steps == 0:
            self._show_mel()
        self.i += 1

# %% ../nbs/06-training-fastspeech.ipynb 7
class Hook:
    def __init__(self, module: Module, func: Callable) -> None:
        self.hook = module.register_forward_hook(partial(func, self))
    
    def __del__(self):
        self.remove()
        
    def __enter__(self, *args):
        return self
    
    def __exit__(self, *args):
        self.remove()
    
    def remove(self):
        self.hook.remove()

# %% ../nbs/06-training-fastspeech.ipynb 8
import wandb
import numpy as np
import matplotlib
import librosa

# %% ../nbs/06-training-fastspeech.ipynb 9
def colorize_mel(mel):
    db = librosa.power_to_db(mel)
    norm_mel = normalize_image(db)
    
    cmap = matplotlib.colormaps['viridis']
    
    return cmap(norm_mel)[::-1]

def normalize(image):
    return (image - np.min(image)) / (np.max(image) - np.min(image))

# %% ../nbs/06-training-fastspeech.ipynb 10
def mel_to_audio(mel: Tensor, sr: int, n_fft: int, hop_length: int, n_iter: int = 32):
    return librosa.feature.inverse.mel_to_audio(mel.numpy() if isinstance(mel, Tensor) else mel, 
                                                sr=sr, 
                                                n_fft=n_fft, 
                                                hop_length=hop_length, 
                                                n_iter=n_iter)

# %% ../nbs/06-training-fastspeech.ipynb 11
class WandBCB(MetricsCB):
    count=100
    def __init__(self, 
                 config: dict, 
                 project: str, 
                 *ms, 
                 xb: Tensor = None, 
                 mel_to_audio: Callable = None,
                 sample_rate: int = 22050,
                 **metrics) -> None:
        fc.store_attr()
        super().__init__(*ms, **metrics)
        
    def _log(self, d: dict, *args, **kwargs):        
        if self.xb:
            mels = self.sample_mels()
            
            wandb.log({ "Mel-Spectrograms": [wandb.Image(colorize_mel(mel)) for mel in mels] })
            
            if self.mel_to_audio:
                audios = list(map(partial(wandb.Audio, sample_rate=self.sample_rate), 
                                  map(self.mel_to_audio, mels)))
                
                wandb.log({ "Audio": audios })
            
    def sample_mels(self):
        with torch.no_grad():
            phones, durations = self.xb[:2]

            mels, _ = to_cpu(learn.model(phones, durations))
        
        return to_cpu(mels)
    
    def before_fit(self, learn):
        wandb.init(project=self.project, config=self.config)
        wandb.watch(learn.model)
    
    def after_batch(self, learn):
        wandb.log({"loss": learn.loss})
    
    def after_fit(self, learn):
        wandb.finish()

# %% ../nbs/06-training-fastspeech.ipynb 12
def count_parameters(model):
    return sum([param.numel() for param in list(model.parameters())])
